# Zookeeper
## Zookeeper Client Demo
使用ZkClient获取节点数据的时候如果出现序列化的错误，需要自己重新实现ZkSerializer类，然后调用ZkClient的setZkSerializer方法<br/>
默认实现是SerializableSerializer类<br/>

## 模拟主从备份master选举
考虑7*24小时向外提供服务的系统，不能有单点故障，于是我们使用集群，采用的是Master+Slave。集群中有一台主机和多台备机，由主机向外提供
服务，备机监听主机状态，一旦主机宕机，备机必需迅速接管主机继续向外提供服务。在这个过程中，从备机选出一台机作为主机的过程，
就是Master选举。

工作服务器启动时，会去ZooKeeper的Servers节点下创建临时节点，并把基本信息写入临时节点。这个过程叫服务注册，系统中的其他服务可以通过
获取Servers节点的子节点列表，来了解当前系统哪些服务器可用，这该过程叫做服务发现。接着这些服务器会尝试创建Master临时节点，谁创建成
功谁就是Master，其他的两台就作为Slave。所有的Work Server必需关注Master节点的删除事件。通过监听Master节点的删除事件，来了解Master
服务器是否宕机（创建临时节点的服务器一旦宕机，它所创建的临时节点即会自动删除）。一旦Master服务器宕机，必需开始新一轮的Master选举。
WorkServer是主工作类；<br/>
NodeInfo用来描述WorkServer的基本信息；

## 分布式锁的实现(还未实现，后续会不断更新)
我们常说的锁是单进程多线程锁，在多线程并发编程中，用于线程之间的数据同步，保护共享资源的访问。而分布式锁，指在分布式环境下，
保护跨进程、跨主机、跨网络的共享资源，实现互斥访问，保证一致性。
分布式锁的实现：<br/>
redis<br/>
zookeeper<br/>
两种方式  
1.使用zookeeper实现分布式锁(读写锁),注意<b>惊群问题</b>



###### 
基于Zookeeper实现分布式锁，其实是不常用的。  
虽然它实现锁十分优雅，但编程复杂，同时还要单独维护一套Zookeeper集群，频繁的Watch对Zookeeper集群的压力还是蛮大的，
如果不是原有的项目中已有Zookeeper，同时锁的量级比较小的话，还是不用为妙。

## 代码使用slf4j的接口，具体日志实现框架用log4j标准输出日志格式：控制台、文件、滚动日期文件、固定大小文件以及ERROR级别日志发送邮件<br/>
####  未完待续

    客户端的核心诉求在于判断自己是否是最小的节点，所以说每个节点的创建者其实不用关心所有的节点变更，它真正关心的应该是比自己序号小的那个节点是否存在！

    1.client调用create()方法创建“/root/lock_”节点，注意节点类型是EPHEMERAL_SEQUENTIAL

    2.client调用getChildren("/root/lock_",false)来获取所有已经创建的子节点，这里并不注册任何Watcher

    3.客户端获取到所有子节点Path后，如果发现自己在步骤1中创建的节点是所有节点中最小的，那么就认为这个客户端获得了锁

    4.如果在步骤3中，发现不是最小的，那么找到比自己小的那个节点，然后对其调用exist()方法注册事件监听

    5.之后一旦这个被关注的节点移除，客户端会收到相应的通知，这个时候客户端需要再次调用getChildren("/root/lock_",false)来确保自己是最小的节点，然后进入步骤3
## java8 list的stream特性
